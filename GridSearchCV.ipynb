{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GridSearchCV.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTAA3CxyQ-Ld"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\r\n",
        "from sklearn.datasets import load_boston, load_breast_cancer\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "import xgboost as xgb\r\n",
        "import lightgbm as lgb\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "from keras.datasets import mnist\r\n",
        "from keras.utils.np_utils import to_categorical\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecDF6D9VRCJm"
      },
      "source": [
        "def algorithm_pipeline(X_train_data, X_test_data, y_train_data, y_test_data, model, param_grid, cv = 10, scoring_fit = \"neg_mean_squared_error\", do_probabilities = False):\r\n",
        "  gs = GridSearchCV (estimator = model, param_grid = param_grid, cv =cv, n_jobs = -1, scoring = scoring_fit, verbose =2)\r\n",
        "\r\n",
        "  fitted_model = gs.fit(X_train_data, y_train_data)\r\n",
        "  if do_probabilities:\r\n",
        "    pred = fitted_model.predict_proba(X_test_data)\r\n",
        "  else:\r\n",
        "    pred = fitted_model.predict(X_test_data)\r\n",
        "    \r\n",
        "    return fitted_model, pred"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkdYFsnMTMk-",
        "outputId": "e87b1ce0-950c-4533-e4a5-65e9a3878b6c"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dvAGYBQfjHd"
      },
      "source": [
        "def preprocess_mnist(x_train, y_train, x_test, y_test):\r\n",
        "    # Normalizing all images of 28x28 pixels\r\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\r\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\r\n",
        "    input_shape = (28, 28, 1)\r\n",
        "    \r\n",
        "    # Float values for division\r\n",
        "    x_train = x_train.astype('float32')\r\n",
        "    x_test = x_test.astype('float32')\r\n",
        "    \r\n",
        "    # Normalizing the RGB codes by dividing it to the max RGB value\r\n",
        "    x_train /= 255\r\n",
        "    x_test /= 255\r\n",
        "    \r\n",
        "    # Categorical y values\r\n",
        "    y_train = to_categorical(y_train, 10)\r\n",
        "    y_test= to_categorical(y_test, 10)\r\n",
        "    \r\n",
        "    return x_train, y_train, x_test, y_test, input_shape\r\n",
        "    \r\n",
        "X_train, y_train, X_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAT9ZS2Kfp8X"
      },
      "source": [
        "def build_cnn(activation = 'relu',\r\n",
        "              dropout_rate = 0.2,\r\n",
        "              optimizer = 'Adam'):\r\n",
        "    model = Sequential()\r\n",
        "    \r\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3),\r\n",
        "              activation=activation,\r\n",
        "              input_shape=input_shape))\r\n",
        "    model.add(Conv2D(64, (3, 3), activation=activation))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "    model.add(Dropout(dropout_rate))\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(128, activation=activation))\r\n",
        "    model.add(Dropout(dropout_rate))\r\n",
        "    model.add(Dense(10, activation='softmax'))\r\n",
        "    \r\n",
        "    model.compile(\r\n",
        "        loss='categorical_crossentropy', \r\n",
        "        optimizer=optimizer, \r\n",
        "        metrics=['accuracy']\r\n",
        "    )\r\n",
        "    \r\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUwD1WcbfuPN",
        "outputId": "377c2bb5-40f7-4b99-f744-367b565f070c"
      },
      "source": [
        "param_grid = {\r\n",
        "              'epochs':[1,2,3],\r\n",
        "              'batch_size':[128]\r\n",
        "              #'epochs' :              [100,150,200],\r\n",
        "              #'batch_size' :          [32, 128],\r\n",
        "              #'optimizer' :           ['Adam', 'Nadam'],\r\n",
        "              #'dropout_rate' :        [0.2, 0.3],\r\n",
        "              #'activation' :          ['relu', 'elu']\r\n",
        "             }\r\n",
        "\r\n",
        "model = KerasClassifier(build_fn = build_cnn, verbose=0)\r\n",
        "\r\n",
        "model, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \r\n",
        "                                       param_grid, cv=5, scoring_fit='neg_log_loss')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.6min finished\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrutSF4sx0Bx",
        "outputId": "3a7fb0e7-487c-4e5f-fca8-be6e202607fe"
      },
      "source": [
        "print(model.best_score_)\r\n",
        "print(model.best_params_)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.04435932706569368\n",
            "{'batch_size': 128, 'epochs': 3}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnSVb2MfzvR7"
      },
      "source": [
        "simpl_mlp = build_cnn()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhkTQroOx1fr",
        "outputId": "485cfc20-97ed-42cc-fc80-188abba908a5"
      },
      "source": [
        "simpl_mlp.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tekXA6Y0cFC"
      },
      "source": [
        "boston = load_boston()\r\n",
        "X = boston.data\r\n",
        "y = boston.target\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slsxzg1Q1f8k",
        "outputId": "8a5a0454-5074-4531-9101-69384c8818ef"
      },
      "source": [
        "model = xgb.XGBRegressor()\r\n",
        "param_grid = {\r\n",
        "    'n_estimators': [400, 700, 1000],\r\n",
        "    'colsample_bytree': [0.7, 0.8],\r\n",
        "    'max_depth': [15,20,25],\r\n",
        "    'reg_alpha': [1.1, 1.2, 1.3],\r\n",
        "    'reg_lambda': [1.1, 1.2, 1.3],\r\n",
        "    'subsample': [0.7, 0.8, 0.9]\r\n",
        "}\r\n",
        "\r\n",
        "model, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \r\n",
        "                                 param_grid, cv=5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 486 candidates, totalling 2430 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   11.3s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:   43.2s\n",
            "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=-1)]: Done 1009 tasks      | elapsed:  5.7min\n",
            "[Parallel(n_jobs=-1)]: Done 1454 tasks      | elapsed:  8.3min\n",
            "[Parallel(n_jobs=-1)]: Done 1981 tasks      | elapsed: 11.6min\n",
            "[Parallel(n_jobs=-1)]: Done 2430 out of 2430 | elapsed: 14.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[13:45:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZxKLN8g54gQ",
        "outputId": "c1f71eee-adbf-4a73-b091-6f2bb8f83da4"
      },
      "source": [
        "print(model.best_score_)\r\n",
        "print(model.best_params_)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-12.148007954095755\n",
            "{'colsample_bytree': 0.8, 'max_depth': 20, 'n_estimators': 400, 'reg_alpha': 1.2, 'reg_lambda': 1.3, 'subsample': 0.8}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}